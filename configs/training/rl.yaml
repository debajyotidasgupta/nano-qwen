# GRPO / RL configuration
optimizer:
  lr: 5.0e-7
  min_lr: 5.0e-8
  weight_decay: 0.1
  beta1: 0.9
  beta2: 0.95
  eps: 1.0e-8
  grad_clip: 1.0
  fused: true

scheduler:
  type: cosine
  warmup_steps: 50
  total_steps: 2000

batch:
  micro_batch_size: 1
  gradient_accumulation_steps: 32
  max_seq_len: 8192

precision:
  dtype: bfloat16
  grad_scaler: false

distributed:
  dp_size: -1
  tp_size: 1
  pp_size: 1
  ep_size: 1
  cp_size: 1
  fsdp_enabled: true

checkpoint:
  save_interval: 200
  save_dir: checkpoints/rl
  async_save: true
  resume_from: null

logging:
  log_interval: 5
  wandb_project: nanogpt-rl
  wandb_enabled: false
  tensorboard_enabled: true
  tensorboard_dir: tb_logs/rl

grpo:
  group_size: 16
  clip_ratio: 0.2
  kl_coef: 0.01
  temperature: 0.7
  max_gen_len: 2048
  reward_types:
    - verifiable
    - model

dpo:
  beta: 0.1
  label_smoothing: 0.0
  reference_free: false
