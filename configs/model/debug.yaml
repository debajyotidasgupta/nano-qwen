hidden_size: 256
num_hidden_layers: 6
num_attention_heads: 8
num_key_value_heads: 2
intermediate_size: 688
vocab_size: 32000
max_position_embeddings: 2048
rms_norm_eps: 1.0e-6
hidden_act: silu
attention_bias: false
qk_norm: true
rope_theta: 10000.0
tie_word_embeddings: true
gradient_checkpointing: false
initializer_range: 0.02
